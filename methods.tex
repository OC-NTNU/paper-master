\section{Methods}

An evaluation was conducted to compare the performance of the two information extraction approaches on the specified task. Statistical information extraction systems traditionally follow the bottom-up approach, and an existing information exaction system was therefore selected to provide the benchmark for the bottom-up approach. On the other hand, the top-down approach is rarely taken in the literature. It was therefore necessary to develop a prototype top-down information extraction system for the sake of comparison.

\subsection{Bottom-up system: TEES}

To act as a benchmark bottom-up system, the Turku Event Extraction System (TEES) \citep{bjo11ddi} was selected. TEES was selected for the evaluation because it is has shown state-of-the-art performance over several years of development, can extract events with arbitrary structures, can be trained with custom data sets and the source code is publicly available\footnote{\url{https://github.com/jbjorne/TEES}}. TEES has been developed for BioNLP, and has attained high scores on a number of shared tasks, including BioNLP 2009 (1st place) \citep{bjo09}, BioNLP 2011 (1st place in 4/8 tasks) \citep{bjo11} and Drug-Drug Interactions 2011 Challenge (4th place)\citep{bjo11ddi}.

The TEES pipeline consists of the following steps: Preprocessing, Named Entity Recognition, Trigger Detection, Edge Detection and Unmerging. 

Preprocessing consists of sentence splitting, constituency parsing and conversion to Stanford dependency representation. Sentence splitting is normally conducted using the GENIA sentence splitter\footnote{\url{http://www.nactem.ac.uk/y-matsu/geniass/}}, and parsing normally using the BLLIP-parser \citep{cha05} with the McClosky model for biomedical text \citep{mcc08}. Conversion to dependency format is normally performed by the Stanford dependency converter \citep{dem08}. Because the textual materials in the experiment conducted here were not of the biomedical domain, the Stanford parser \citep{kle03} was used instead for preprocessing.

The Named Entity Recognition, Trigger Detection, Edge Detection and Unmerging components are all machine learning-based multi-class classification components that use the $SVM^{MULTICLASS}$ implementation of SVM for classification.

TEES has participated mostly in event extraction-focused shared tasks, in which named entities were given as input to the system, so the Named Entity Component is normally not used, but can be included into the pipeline if required by the task, which is the case in the experiment presented here. The Named Entity Component makes a linear pass over all the tokens in the sentence, classifying every token as belonging to either one of the entity categories or as not an entity. Normally each single token is counted as an independent entity, but if two or more subsequent tokens are classified as belonging to the same class, they are merged to form a multi-token entity if a multi-token entity with the exact same text string can be found in the training data.

Trigger Detection makes another linear pass over the tokens in the sentence, detecting event trigger words. Every token is either classified as belonging to one of the event categories, or as not an event trigger. In the same way as with NER, multiple subsequent tokens can be merged to a single trigger if given the same class, and a trigger with the exact same text string can be found in the training data.

Edge Detection detects arguments of the triggered events. Every event is paired with every other event and entity, and the classifier determines which argument relation type holds between the pair, if any. Because this scheme lets events take not only entities, but also events as argument, this can create events with any structure desired.

In case of overlapping events, i.e. events that share some trigger, some cleaning up is required to separate the events. This is performed by the Unmerging step, which uses a classifier to determine whether an argument branch should be unmerged into a separate event. 

\subsection{Top-down system: Pattern matching}

In order to benchmark the top-down approach, an information extraction system had to be developed that followed this approach. Inspection of the data revealed that trigger words for events were relatively unambiguous. It was therefore concluded that a deterministic pattern matching system would be sufficient to provide an estimate for the performance of the top-down approach on the task at hand.

The prototype system uses a two-step pipeline. The first step detects change event triggers and entity arguments. The second step tries to detect interaction events in sentences where are multiple change events. In addition, a preprocessing step handles sentence splitting, lemmaization and parsing. The same preprocessing machinery is used for both systems in the experiment.

Figure \ref{pattern_exmpl} gives two example of patterns used in the first step. Each pattern consists of a trigger lemma, an event type and an argument type with a dependency path. The extraction process is illustrated in Figure \ref{dep_pattern}. During extraction, the system first tries to match the trigger lemma against the lemmas used in the sentence. Trigger lemma matches for the two patterns provided in Figure \ref{pattern_exmpl} are shown in blue. For each trigger lemma match, the system then tries to match the argument dependency path of the pattern to the dependency representation of the sentence. In the argument dependency path, the letter T represent the node of the trigger word, and the letter S, which will be explained shortly, can match any node. The matching paths are coloured in red in the example. 

After matching the pattern, the trigger node becomes annotated as a change event of the type specified in the pattern. The subtree rooted at the node labelled as S will become the theme argument of the change event. As shown in the example, sometimes the trigger node lies in the subtree of the S node, in which case that branch is pruned away, extracting "\emph{concentrations of CO2}" rather than "\emph{Increasing concentrations of CO2}" as the argument. The argument becomes annotated as an entity with the entity category specified in the pattern, which can be either VAR (variable) or THN (thing). 

\begin{figure}
\begin{center}
\begin{tabular}{  l  l  }
TRIGGER "increase"	& TRIGGER "decline" \\
TYPE increase & TYPE decrease \\
VAR S amod T & VAR T prep "in" pobj S \\
\end{tabular}
\end{center}
\caption{Example of two patterns for change events}
\label{pattern_exmpl}
\end{figure}

\begin{figure}
\begin{center}
\begin{dependency}[theme = simple]
	\begin{deptext}
	Increasing \& concentrations \& of \& CO2 \& cause \& a \& strong \& decline \& in \& growth \& . \\
	\end{deptext}
	\depedge{2}{1}{AMOD}
	\depedge{2}{3}{PREP}
	\depedge{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge{8}{9}{PREP}
	\depedge{9}{10}{POBJ}
\end{dependency}

\begin{dependency}[theme = simple]
	\begin{deptext}
	\textcolor{blue}{Increasing} \& concentrations \& of \& CO2 \& cause \& a \& strong \& \textcolor{blue}{decline} \& in \& growth \& . \\
	\end{deptext}
	\depedge{2}{1}{AMOD}
	\depedge{2}{3}{PREP}
	\depedge{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge{8}{9}{PREP}
	\depedge{9}{10}{POBJ}
\end{dependency}

\begin{dependency}[theme = simple]
	\begin{deptext}
	\textcolor{blue}{Increasing} \& \textcolor{red}{concentrations} \& of \& CO2 \& cause \& a \& strong \& \textcolor{blue}{decline} \& \textcolor{red}{in} \& \textcolor{red}{growth} \& . \\
	\end{deptext}
	\depedge[edge style=red]{2}{1}{AMOD}
	\depedge{2}{3}{PREP}
	\depedge{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge[edge style=red]{8}{9}{PREP}
	\depedge[edge style=red]{9}{10}{POBJ}
\end{dependency}

\begin{dependency}[theme = simple]
	\begin{deptext}
	\textcolor{blue}{Increasing} \& \textcolor{brown}{concentrations} \& \textcolor{brown}{of} \& \textcolor{brown}{CO2} \& cause \& a \& strong \& \textcolor{blue}{decline} \& \textcolor{red}{in} \& \textcolor{brown}{growth} \& . \\
	\end{deptext}
	\depedge[edge style=red]{2}{1}{AMOD}
	\depedge[edge style=brown]{2}{3}{PREP}
	\depedge[edge style=brown]{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge[edge style=red]{8}{9}{PREP}
	\depedge[edge style=red]{9}{10}{POBJ}
\end{dependency}

\end{center}
\caption{Example of matching process for change events}
\label{dep_pattern}
\end{figure}

For the second step, where interaction events are extracted, simpler patterns are used, as shown in Figure \ref{iep_exmpl}. In addition to the type parameter, \emph{cause} patterns have an \emph{agent} parameter, which specifies which of the two change events gets marked as the agent in case of a match. Finally, all interaction event patterns have a list of sub-patterns. Each sub-pattern consists of a location and a string. During matching, only sentences with multiple extracted change events are considered. For every pair of adjacent change events, the sentence is divided into three parts: The words before the first change event (BEFORE), the words between the change events (BETWEEN) and the words after the second change event (AFTER). This is illustrated in Figure \ref{iep_split}. If the strings of all the sub-patterns match in the current location, then an interaction event of the corresponding type is annotated at the text span matched by the first sub-pattern. 

As the observant reader may notice, correlations do not have any parameter that specifies which argument event takes which argument role. This is because it was observed that the pattern itself is not sufficient to determine which argument takes which role. As a default, the leftmost argument is chosen as the theme and the rightmost as co-theme.

There are several other situations not handled by the current prototype system, including the grammatical categories (and, or, refexp), interactions that take entities as one or both of the arguments and the agent arguments of causal change events.

\begin{figure}
\begin{center}
\begin{tabular}{  l  l  }
TYPE cause & TYPE correlate \\
AGENT left	& AFTER correlated \\
BETWEEN cause & BETWEEN and \\
\end{tabular}
\end{center}
\caption{Example of two patterns for interaction events}
\label{iep_exmpl}
\end{figure}

\begin{figure}
\begin{center}

\textbf{[Increasing concentrations of CO2] cause a strong [decline in growth].}

\begin{tabular}{  l  l  }
BEFORE & \\
BETWEEN & cause a strong \\
AFTER & . \\
\end{tabular}

\end{center}
\caption{Splitting a sentence for matching of interaction event patterns}
\label{iep_split}
\end{figure}

The patterns used in the experiment were manually developed from eight of the papers in the corpus, with the remaining two held out as test data. For every annotated event in the development corpus, a pattern was written that would extract that event. Events that were impossible to extract with the types of patterns explained above, such as interactions between non-adjacent change events were ignored. To improve performance, each pattern was manually evaluated against the development data, and patterns that yielded a high ratio of false positives on the development data were excluded. 

One particular group of patterns that created exceptionally many false positives was correlations triggered by single prepositions, such as ''in'', ''with'' or ''under''. This group represented a significant proportion of all correlations in the development data, but was nevertheless removed from the final set of patterns, due to the high rate of false negatives. Manual inspection of the corpus has revealed that the problem of false positives can be avoided by using patterns that match against the dependency structure, akin to the patterns used for change events, for these correlations, but this was not done for the prototype system evaluated here.

\subsection{Evaluation methods}

TEES was evaluated by five-fold cross-validation, each fold consisting of two papers. As eight papers had been used during development of the pattern matching system, the pattern matching system was evaluated once only, using the two remaining papers as test data.

In the evaluation, an element is matched to an element in the gold standard if the text spans exhibit any degree of overlap, thus abstracting away from exact scoping of text spans. A predicted trigger was counted as a true positive if it matched an element of the same annotation category in the gold standard, and a false positive if it didn't. A trigger in the gold standard was counted as a false negative if it could not be matched to a predicted trigger of the same category. 