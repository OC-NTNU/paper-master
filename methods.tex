\section{Systems}

Initial experiments showed that the traditional information extraction pipeline performed poorly on the extraction task defined above. We hypothesised that the performance of the traditional pipeline on our extraction task was degreaded by the fact that trigger words are not as indicative of entities in our annotation scheme as they are in most biomedical annotation schemes. This is mainly because whether a phrase corresponds to a variable of interest strongly depends on the context. As an example, compare the usage of $CO_2$ n the following sentences:

\begin{enumerate}
	\item "$CO_2$ is a colourless, odourless gas." 
	\item "Increasing concentrations of $CO_2$ cause a strong decline in growth."
\end{enumerate}

To test the hypothesis, we conducted an experiment which evaluated a system using an alternative pipeline against a basine system using the canonical pipeline. This section presents both systems.

\subsection{Baseline system: TEES}

To act as a benchmark for the traditional information extraction pipeline, the Turku Event Extraction System (TEES) \citep{bjo11ddi} was selected. TEES was selected for the evaluation because it is has shown state-of-the-art performance over several years of development, can extract events with arbitrary structures and can be trained with custom data sets. TEES has been developed for BioNLP, and has attained high scores on a number of shared tasks, including BioNLP 2009 (1st place) \citep{bjo09}, BioNLP 2011 (1st place in 4/8 tasks) \citep{bjo11} and Drug-Drug Interactions 2011 Challenge (4th place)\citep{bjo11ddi}. The source code is publicly available\footnote{\url{https://github.com/jbjorne/TEES}}.

The TEES pipeline consists of the following steps: Preprocessing, Named Entity Recognition, Trigger Detection, Edge Detection and Unmerging. 

Preprocessing consists of sentence splitting, constituency parsing and conversion to Stanford dependency representation\citep{dem08}. When TEES is applied in the biomedical domain, sentence splitting is conducted using the GENIA sentence splitter\footnote{\url{http://www.nactem.ac.uk/y-matsu/geniass/}}, and parsing using the BLLIP-parser \citep{cha05} with the McClosky model for biomedical text \citep{mcc08}. Conversion to dependency format is performed by the Stanford dependency converter \citep{dem08}. Because the textual material in our corpus was not from the biomedical domain, the domain independent Stanford parser \citep{kle03} was instead used for preprocessing in the experiment presented in this paper.

The Named Entity Recognition, Trigger Detection, Edge Detection and Unmerging components are all implemented as machine learning-based multiclass classifiers that use the $SVM^{MULTICLASS}$ implementation of SVM for classification.

TEES has participated mostly in event extraction-focused shared tasks, in which named entities were given as input to the system, so the NER component is normally not used, but can be included into the pipeline if required by the task, which was the case in the experiment presented in this paper. The NER component makes a linear pass over all the tokens in the sentence, classifying every token as belonging to either one of the entity categories or as not an entity. Normally, each individual token is treated as an independently extracted entity, but if two or more subsequent tokens are classified as belonging to the same class, they are merged to form a multi-token entity if a multi-token entity with the exact same text string can be found in the training data. Whereas this strategy works well for the biomedical domain where the length of entity text spans is normally three words or less, it fails to produce entities of unbounded length as required by our annotation scheme for climate change science. However, as described below, we define the scoring metrics in such a way that this should not negatively influence the performance of TEES, based on the simplifying assumption that identifying the correct entity boundaries is a task of a post-processing component.	

Trigger Detection also makes a linear pass over the tokens in the sentence, detecting trigger words for event categories. This is also cast as a multiclass classification problem, where every token is either classified as belonging to one of the event categories, or as \emph{none}, i.e. not a trigger for any event category. In the same way as with NER, multiple subsequent tokens can be merged to a single trigger if given the same class, and a trigger with the exact same text string can be found in the training data.

Edge Detection detects arguments of the triggered events. First, the system generates all the argument relation candidates, which are all pairs of events and entities or events and events. For every candidate, determining whether an argument relation holds between the two triggers or not is again cast as a multiclass classification problem, where the possible classes consists of all posssible argument relations (theme, co-theme, agent) as well as the none-relation. Because this scheme tries to detect argument relations between not only events and entities, but also between pairs of events, this can create complex events with any arbitrary structure. Note here that detection only operates with pairs of \emph{triggers}, so that it can detect for instance that an agent relation holds between a cause event trigger and a change event trigger, without regards to whether the argument structure of the change event has been inferred yet.

In case of overlapping events, i.e. events that share some trigger, some cleaning up is required to separate the events. This is performed by the Unmerging step, which uses a classifier to determine whether an argument branch should be unmerged into a separate event. 

\subsection{Alternative pipeline}

The main observation that motivated our change to the canonical pipeline was that entities in our annotation scheme appeared hard to extract directly from text without any information about the change events in the sentence. To ammend this, we split event extraction into to subtasks - change event extraction and interaction event extraction - and reorganized the order of the components, so that change event extraction comes first, before entity extraction. To the best of our knowledge, no out-of-the-box information extraction exist that allows such customization to the pipepline. TEES could not straightforwardly be modified to support this modification, because the features used for entity extraction are not designed to exploit the knowledge provided by the change event extraction step.

A deterministic pattern matching system was developed as a prototype system using our alternative pipeline. This prototype system uses a two-step pipeline. The first step detects change event triggers and entity arguments. The second step tries to detect interaction events in sentences with multiple change events. In addition, a preprocessing step handles sentence splitting, lemmatisation and parsing. The same preprocessing machinery is used for both systems in the experiment.

Figure \ref{pattern_exmpl} gives two example of patterns used in the first step. Each pattern consists of a trigger lemma, an event type and an argument type with a dependency path. The extraction process is illustrated in Figure \ref{dep_pattern}. During extraction, the system first tries to match the trigger lemma against the lemmas used in the sentence. Trigger lemma matches for the two patterns provided in Figure \ref{pattern_exmpl} are shown in blue. For each trigger lemma match, the system then tries to match the argument dependency path of the pattern to the dependency representation of the sentence. In the argument dependency path, the letter T represent the node of the trigger word, and the letter S, which will be explained shortly, can match any node. The matching paths are coloured in red in the example. 

After matching the pattern, the trigger node becomes annotated as a change event of the type specified in the pattern. The subtree rooted at the node labelled as S will become the theme argument of the change event. As shown in the example, sometimes the trigger node lies in the subtree of the S node, in which case that branch is pruned away, extracting "\emph{concentrations of CO2}" rather than "\emph{Increasing concentrations of CO2}" as the argument. The argument becomes annotated as an entity with the entity category specified in the pattern, which can be either VAR (variable) or THN (thing). 

\begin{figure}
\begin{center}
\begin{tabular}{  l  l  }
TRIGGER "increase"	& TRIGGER "decline" \\
TYPE increase & TYPE decrease \\
VAR S amod T & VAR T prep "in" pobj S \\
\end{tabular}
\end{center}
\caption{Example of two patterns for change events}
\label{pattern_exmpl}
\end{figure}

\begin{figure}
\begin{center}
\begin{dependency}[theme = simple]
	\begin{deptext}
	Increasing \& concentrations \& of \& CO2 \& cause \& a \& strong \& decline \& in \& growth \& . \\
	\end{deptext}
	\depedge{2}{1}{AMOD}
	\depedge{2}{3}{PREP}
	\depedge{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge{8}{9}{PREP}
	\depedge{9}{10}{POBJ}
\end{dependency}

\begin{dependency}[theme = simple]
	\begin{deptext}
	\textcolor{blue}{Increasing} \& concentrations \& of \& CO2 \& cause \& a \& strong \& \textcolor{blue}{decline} \& in \& growth \& . \\
	\end{deptext}
	\depedge{2}{1}{AMOD}
	\depedge{2}{3}{PREP}
	\depedge{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge{8}{9}{PREP}
	\depedge{9}{10}{POBJ}
\end{dependency}

\begin{dependency}[theme = simple]
	\begin{deptext}
	\textcolor{blue}{Increasing} \& \textcolor{red}{concentrations} \& of \& CO2 \& cause \& a \& strong \& \textcolor{blue}{decline} \& \textcolor{red}{in} \& \textcolor{red}{growth} \& . \\
	\end{deptext}
	\depedge[edge style=red]{2}{1}{AMOD}
	\depedge{2}{3}{PREP}
	\depedge{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge[edge style=red]{8}{9}{PREP}
	\depedge[edge style=red]{9}{10}{POBJ}
\end{dependency}

\begin{dependency}[theme = simple]
	\begin{deptext}
	\textcolor{blue}{Increasing} \& \textcolor{brown}{concentrations} \& \textcolor{brown}{of} \& \textcolor{brown}{CO2} \& cause \& a \& strong \& \textcolor{blue}{decline} \& \textcolor{red}{in} \& \textcolor{brown}{growth} \& . \\
	\end{deptext}
	\depedge[edge style=red]{2}{1}{AMOD}
	\depedge[edge style=brown]{2}{3}{PREP}
	\depedge[edge style=brown]{3}{4}{POBJ}
	\depedge{5}{2}{NSUBJ}
	\depedge{5}{8}{DOBJ}
	\depedge[arc angle=55]{8}{6}{DET}
	\depedge[arc angle=15]{8}{7}{AMOD}
	\depedge[edge style=red]{8}{9}{PREP}
	\depedge[edge style=red]{9}{10}{POBJ}
\end{dependency}

\end{center}
\caption{Example of matching process for change events}
\label{dep_pattern}
\end{figure}

For the second step, where interaction events are extracted, simpler patterns are used, with examples of this kind of pattern shown in Figure \ref{iep_exmpl}. In addition to the type parameter, \emph{cause} patterns have an \emph{agent} parameter, which specifies which of the two change events gets marked as the agent in case of a match. Finally, all interaction event patterns have a list of sub-patterns. Each sub-pattern consists of a location and a string. During matching, only sentences with multiple extracted change events are considered. For every pair of adjacent change events, the sentence is divided into three parts: The words before the first change event (BEFORE), the words between the change events (BETWEEN) and the words after the second change event (AFTER). This is illustrated in Figure \ref{iep_split}. If the strings of all the sub-patterns match in the specified location, then an interaction event of the corresponding type is annotated at the text span matched by the first sub-pattern. 

As the observant reader may have noticed, correlations do not have any parameter that specifies which argument event takes which argument role. This is because it was observed that the pattern itself is not sufficient to determine which argument takes which role. As a default, the leftmost argument is chosen as the theme and the rightmost as co-theme.

\begin{figure}
\begin{center}
\begin{tabular}{  l  l  }
TYPE cause & TYPE correlate \\
AGENT left	& AFTER correlated \\
BETWEEN cause & BETWEEN and \\
\end{tabular}
\end{center}
\caption{Example of two patterns for interaction events}
\label{iep_exmpl}
\end{figure}

\begin{figure}
\begin{center}

\textbf{[Increasing concentrations of CO2] cause a strong [decline in growth].}

\begin{tabular}{  l  l  }
BEFORE & \\
BETWEEN & cause a strong \\
AFTER & . \\
\end{tabular}

\end{center}
\caption{Splitting a sentence for matching of interaction event patterns}
\label{iep_split}
\end{figure}

As our corpus consisted of 10 annotated papers, the patterns used in the experiment were manually developed from eight of the papers in the corpus, with the remaining two held out as test data. For every annotated event in the development corpus, a pattern was written that would extract that event. Events that were impossible to extract with the types of patterns explained above, such as interactions between non-adjacent change events were ignored. To improve performance, each pattern was manually evaluated against the development data, and patterns that yielded a high ratio of false positives on the development data were excluded. 

One particular group of patterns that created exceptionally many false positives was correlations triggered by single prepositions, such as ''in'', ''with'' or ''under''. This group represented a significant proportion of all correlations in the development data, but was nevertheless removed from the final set of patterns, due to the high rate of false negatives. While conducting the experiment described here, it was observed that the problem of false positives can be avoided by using patterns that match against the dependency structure, akin to the patterns used for change events, for this type of correlations.
