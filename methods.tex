\section{Methods}

An evaluation was conducted to compare the performance of the two information extraction approaches on the specified task. Statistical information extraction systems traditionally follow the bottom-up approach, and an existing information exaction system was therefore selected to provide the benchmark for the bottom-up approach. On the other hand, the top-down approach is rarely taken in the literature. It was therefore necessary to develop a prototype top-down information extraction system for the sake of comparison.

To act as a benchmark bottom-up system, the Turku Event Extraction System (TEES) \citep{bjö11ddi} was selected. TEES was selected for the evaluation because it is has shown state-of-the-art performance over several years of development, can extract events with arbitrary structures, can be trained with custom data sets and the source code is publicly available\footnote{\url{https://github.com/jbjorne/TEES}}. TEES has been developed for BioNLP, and has attained high scores on a number of shared tasks, including BioNLP 2009 (1st place) \citep{bjö09}, BioNLP 2011 (1st place in 4/8 tasks) \citep{bjö11} and Drug-Drug Interactions 2011 Challenge (4th place) \citep{bjö11ddi}.

\todo[inline]{What should I write more on TEES?}

In order to benchmark the top-down approach, an information extraction system had to be developed that followed this approach. Inspection of the data revealed that trigger words for events were relatively unambiguous. It was therefore concluded that a deterministic pattern matching system would be sufficient to provide an estimate for the performance of the top-down approach on the task at hand.

In the system, a pattern is defined as a partial dependency graph that signals the presence of an event. During information extraction, the system parses the text with the Stanford parser\citep{kle03}, and an event is detected for every pattern that matches the dependency parse tree of the sentence. In case of a match, each pattern specifies which node(s) in the dependency tree should be labelled as the event trigger, and which parts of the dependency tree that should be labelled as the arguments. 

A set of patterns was manually developed from eight of the papers in the corpus, with the remaining two held out as test data. For every annotated event in the corpus, a pattern was written that would extract that event. To improve performance, each pattern was manually evaluated against the eight papers, and patterns that yielded a high ratio of false positives on the development data were excluded.

\todo[inline]{I am unsure how much detail is interesting about the PMS, and how to make it appear like we did not only do this because we were lazy.}

TEES was evaluated by five-fold cross-validation, each fold consisting of two papers. As eight papers had been used during development of the pattern matching system, the pattern matching system was evaluated once only, using the two remaining papers as test data.

\todo[inline]{How are matches counted in the evaluation procedure?}