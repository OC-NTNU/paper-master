\section{Introduction}

Information extraction is the task of extracting structured information from natural language text. Historically, information extraction research focused on named entity recognition (NER), that is, figuring out which entities are mentioned in a piece of text. As research progressed, researchers started to turn their attention to gradually more complex tasks, such as relation extraction - the task of discovering the relations that hold between the extracted entities, and later event extraction, which aims to extract more information patterns, such as n-ary relations, or relations between relations, an example of the latter being discovering temporal ordering.

Machine learning based event extraction systems tend to use a pipeline of components, in which the first extracts entities, a subsequent component extracts triggers for events, and finally a component tries to determine participant relations between entities and events, and potenitally event-event relations. The pipeline architecture has two drawbacks: Error propagation, because each component makes hard choices that cannot be undone by downstream components, and the inability to model constraints from entities to events. Some recent research effort has therefore focused on joint extraction architecture that try to optimize globally accross all components. However, joint extraction architectures have not reached the level of maturity required for state-of-the-art performance, and have other drawbacks, such as the increased complexity of learning a joint probability distribution, that make them infeasible for certain circumstances, such as when training data is scarce. Off-the-shelf joint information extraction systems are also lacking.\todo{Verify that these claims are backed up by related work section}

The canonical information extraction pipeline architecture has worked well for many extraction tasks, but this paper argues that there are other ways of structuring the information extraction pipeline that can potentially yield better results for certain extraction tasks.

This paper presents an experiment made in the climate change domain showing the benefit from customizing the information extraction pipeline for the domain at hand. 

The main contributions of this paper are:

\begin{itemize}

\item Showing that customizing the extraction pipeline can yield improved performance on certain tasks.

\item Describing two types of changes that can be made to the pipeline: Reordering the components, and splitting a component into smaller components.

\item Exploring heuristics that point out which extraction pipeline yields the best results for a certain extraction task.

\item Introducing text mining in the climate change domain.

\end{itemize}


Section 2 will introduce text mining in the climate change domain, section 3 will introduce the information extraction systems used to conduct the experiment. The experiment itself will be described in section 4, and the results provided in the same section. Finally, section 5 will discuss the results and provide pointers for future work. 

